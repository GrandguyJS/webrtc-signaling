<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>WebRTC B</title>
</head>
<body>
  <h1>Client B</h1>
  <video id="remote" autoplay playsinline></video>
  <div style="display: div; flex-direction: column;">
      <label>
        <input type="checkbox" id="toggleVideo">
        Video on
      </label>
      <br>
      <label>
        <input type="checkbox" id="toggleAudio" checked>
        Audio on
      </label>
      <br>
      <input type="file" id="audioFile" accept="audio/mp3,audio/mpeg">
  </div>
  <script>
    const id = "B";
    const target = "A";

    const ws = new WebSocket("wss://domain");
    const pc = new RTCPeerConnection({
        iceServers: [
            { urls: 'stun:stun.l.google.com:19302' }, // Google's public STUN server
            { urls: "turn:global.replay.metered.ca:80", username: "openai", credential: "openai" }
        ]
    });

    const remoteVideo = document.getElementById("remote");
    let localStream;

    ws.onopen = () => {
      ws.send(JSON.stringify({id}));
    };

    ws.onmessage = async (event) => {
      const data = JSON.parse(event.data);
      if (data.type === "ready") {
        setTimeout(async () => { 
            const offer = await pc.createOffer(); 
            await pc.setLocalDescription(offer); 
            ws.send(JSON.stringify({to: target, sdp: pc.localDescription})); 
        }, 2000);
      } else if (data.type === "audio") {
        const bytes = Uint8Array.from(atob(data.data), c => c.charCodeAt(0));
        const blob = new Blob([bytes], { type: "audio/mpeg" });
        const url = URL.createObjectURL(blob);

        const audio = new Audio(url);
        audio.play();
        return;
      } else if (data.sdp) {
        await pc.setRemoteDescription(new RTCSessionDescription(data.sdp));
        if (data.sdp.type === "offer") {
          const answer = await pc.createAnswer();
          await pc.setLocalDescription(answer);
          ws.send(JSON.stringify({to: target, sdp: pc.localDescription}));
        }
      } else if (data.ice) {
        try { await pc.addIceCandidate(data.ice); } catch(e) {}
      }
    };

    pc.onicecandidate = (e) => {
      if (e.candidate) ws.send(JSON.stringify({to: target, ice: e.candidate}));
    };

    pc.ontrack = (e) => {
      remoteVideo.srcObject = e.streams[0];
    };

    navigator.mediaDevices.getUserMedia({video:true, audio:true})
      .then(stream => {
        localStream = stream;
        stream.getTracks().forEach(track => pc.addTrack(track, stream));

        const videoTrack = localStream.getVideoTracks()[0];
        const audioTrack = localStream.getAudioTracks()[0];

        if (videoTrack) {
        videoTrack.enabled = document.getElementById("toggleVideo").checked;
        }
        if (audioTrack) {
        audioTrack.enabled = document.getElementById("toggleAudio").checked;
        }
      });

    // Mute / Cut video

    document.getElementById("toggleVideo").addEventListener("change", (e) => {
      const t = localStream?.getVideoTracks()[0];
      if (t) t.enabled = e.target.checked;
    });

    document.getElementById("toggleAudio").addEventListener("change", (e) => {
      const t = localStream?.getAudioTracks()[0];
      if (t) t.enabled = e.target.checked;
    });

    // mp3 file
    document.getElementById("audioFile").addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      const arrayBuffer = await file.arrayBuffer();
      const base64 = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));

      ws.send(JSON.stringify({
        to: target,
        type: "audio",
        name: file.name,
        data: base64
      }));
    });
  </script>
</body>
</html>
